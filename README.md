# AInte â€“ AI Integration with FastAPI, OpenAI & RAG

AInte is a complete demo project that showcases how to integrate  
LLM models, embeddings, and RAG
into a FastAPI backend.

This project includes:

âœ… Chat endpoint  
âœ… File upload + embedding generation  
âœ… Vector storage using ChromaDB  
âœ… RAG queries with semantic search  
âœ… Simple frontend (HTML/JS) for testing  

---

## ğŸš€ Features

### **1. Chat Endpoint**
A simple API endpoint that communicates with OpenAIâ€™s Chat models  
(default: `gpt-4o-mini`).

### **2. File Upload + Embeddings**
Users can upload documents which are then embedded and stored  
inside ChromaDB along with metadata.

### **3. RAG Query**
Ask a question â†’ semantic search runs â†’ the top-matched context is sent  
to the LLM for an enriched and accurate answer.

### **4. Frontend Demo**
A very small HTML interface used for testing:
- Chat
- Upload
- Ask (RAG)

---

## ğŸ“ Project Structure

AInte/
â”‚
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ main.py # API endpoints & routing
â”‚ â”œâ”€â”€ openai_client.py # OpenAI API wrapper
â”‚ â”œâ”€â”€ rag.py # RAG logic (ChromaDB + embeddings)
â”‚ â”œâ”€â”€ schemas.py # Pydantic models (validation)
â”‚ â”œâ”€â”€ utils.py # File upload helpers
â”‚ â””â”€â”€ static/
â”‚ â””â”€â”€ index.html # Minimal frontend demo
â”‚
â”œâ”€â”€ .env.example # Environment variables template
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ .gitignore # Ignored files
â””â”€â”€ README.md # Documentation


---

## ğŸ”§ Installation

### 1. Clone the repository
```bash
git clone https://github.com/YOUR-USERNAME/AInte.git
cd AInte
```

  2. Create a virtual environment
```
python -m venv .venv
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\activate      # Windows
```
  3. Install Dependecies
```
pip install -r requirements.txt
```
  4. Create your environment file
```
cp .env.example .env
```
->Fill in your OpenAI API Key inside .env.

---

## â–¶ï¸ Running the Server

```
uvicorn app.main:app --reload
```

Then open your browser at:

```
http://localhost:8000
```

You will see:

- Chat section  
- Upload section  
- RAG Query section  

All inside the simple HTML interface.

---
âœ…ğŸ“„ PDF Text Extraction (New Feature)
 
AInte now supports automatic text extraction from PDF documents using PyMuPDF (fitz).

When a user uploads a PDF:

The server reads the file

Extracts clean text from each page

Stores the extracted content inside ChromaDB

Makes it searchable via RAG queries

Supported formats:

âœ” .pdf â€” full text extraction

âœ” .txt â€” plain text read

âœ˜ Other binary files return: "[unsupported file type]"

This enables real Retrieval-Augmented Generation (RAG), allowing the system to give accurate answers based on the actual content of the uploaded PDF.

## ğŸ§  API Usage

### **Chat**
POST â†’ `/chat`

Body:
```
{
  "prompt": "Your message here"
}
```

---

### **Upload Document**
POST â†’ `/upload`

Multipart form-data:
```
file: <your_file>
```

---

### **RAG Query**
POST â†’ `/query`

Body:
```
{
  "query": "Your question",
  "top_k": 3
}
```

---

## ğŸ— Future Improvements

- Chunking for large PDF files  
- Proper PDF parsing (PyMuPDF / pdfplumber)  
- Authentication (API key / JWT)  
- Dockerfile + container deployment  
- Move vector DB from local ChromaDB â†’ Pinecone / Weaviate  
- Replace HTML with React or Next.js frontend  
- Add retry logic for OpenAI rate limits  
- Add tests with pytest  

